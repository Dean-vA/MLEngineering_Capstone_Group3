{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/Deanis/MLEngineering_Capstone_Group3/blob/main/notebooks/pipeline.i:pynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ],
      "metadata": {
        "id": "DNuP8m0WC1hH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "SAA_0UJpC__P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdw-CtYLCxAd",
        "outputId": "e35070fa-280c-4836-dd39-83818157fecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kfp in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: google-cloud-aiplatform in /usr/local/lib/python3.10/dist-packages (1.28.1)\n",
            "Requirement already satisfied: click<9,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kfp) (8.1.6)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /usr/local/lib/python3.10/dist-packages (from kfp) (0.15)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from kfp) (2.11.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.1 in /usr/local/lib/python3.10/dist-packages (from kfp) (2.17.3)\n",
            "Requirement already satisfied: kfp-pipeline-spec==0.2.2 in /usr/local/lib/python3.10/dist-packages (from kfp) (0.2.2)\n",
            "Requirement already satisfied: kfp-server-api<2.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from kfp) (2.0.0)\n",
            "Requirement already satisfied: kubernetes<27,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kfp) (26.1.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.13.0 in /usr/local/lib/python3.10/dist-packages (from kfp) (3.20.3)\n",
            "Requirement already satisfied: PyYAML<7,>=5.3 in /usr/local/lib/python3.10/dist-packages (from kfp) (6.0.1)\n",
            "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from kfp) (0.10.1)\n",
            "Requirement already satisfied: tabulate<1,>=0.8.6 in /usr/local/lib/python3.10/dist-packages (from kfp) (0.9.0)\n",
            "Requirement already satisfied: urllib3<2.0.0 in /usr/local/lib/python3.10/dist-packages (from kfp) (1.26.16)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.3.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.5.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.22.3)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (3.10.0)\n",
            "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.10.2)\n",
            "Requirement already satisfied: shapely<2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-aiplatform) (1.8.5.post1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.59.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.56.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.48.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.1->kfp) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.1->kfp) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.1->kfp) (1.16.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.1->kfp) (4.9)\n",
            "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in /usr/local/lib/python3.10/dist-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform) (0.12.6)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kfp-server-api<2.1.0,>=2.0.0->kfp) (2023.5.7)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes<27,>=8.0.0->kfp) (67.7.2)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes<27,>=8.0.0->kfp) (1.6.1)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes<27,>=8.0.0->kfp) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib->kubernetes<27,>=8.0.0->kfp) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install kfp pandas transformers google-cloud-storage google-cloud-aiplatform\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kfp\n",
        "from kfp import dsl\n",
        "from kfp.v2 import compiler\n",
        "from kfp.v2.dsl import component\n",
        "import pandas as pd\n",
        "from google.cloud import storage\n",
        "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from google.cloud import aiplatform\n",
        "import os\n",
        "from typing import NamedTuple\n",
        "\n",
        "\n",
        "# Constants\n",
        "bucket_name = 'blank-to-bard'\n",
        "file_name = 'english-dataset.csv'\n",
        "project_id = 'ml-class-group-3-capstone'\n",
        "model_name = 'blank-to-bard'\n"
      ],
      "metadata": {
        "id": "9mPNMgt9C1ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Components"
      ],
      "metadata": {
        "id": "HZUqtZqNDNWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.component(packages_to_install=['pandas', 'google-cloud-storage'])\n",
        "def get_data(bucket_name: str, file_name: str) -> str:\n",
        "    from google.cloud import storage\n",
        "    import pandas as pd\n",
        "    from io import BytesIO\n",
        "\n",
        "    # Initialize a client\n",
        "    storage_client = storage.Client()\n",
        "\n",
        "    # Access the bucket and the file\n",
        "    bucket = storage_client.get_bucket(bucket_name)\n",
        "    blob = bucket.blob(file_name)\n",
        "\n",
        "    # Download the data into a pandas dataframe\n",
        "    data = blob.download_as_text()\n",
        "    data = pd.read_csv(BytesIO(bytes(data, 'utf-8')))\n",
        "\n",
        "    # Return the data as a string\n",
        "    return data.to_csv(index=False)\n",
        "\n",
        "\n",
        "@component(packages_to_install=['transformers', 'sklearn', 'pandas', 'tensorflow'])\n",
        "def preprocess_data(csv_data: str) -> NamedTuple('Outputs', [('train_inputs', str), ('validation_inputs', str), ('train_labels', str), ('validation_labels', str)]):\n",
        "    import pandas as pd\n",
        "    import numpy as np\n",
        "    from io import BytesIO\n",
        "    from transformers import DistilBertTokenizer\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    import tensorflow as tf\n",
        "    from collections import namedtuple\n",
        "\n",
        "    # Read the data from the CSV string\n",
        "    data = pd.read_csv(BytesIO(bytes(csv_data, 'utf-8')))\n",
        "\n",
        "    # Tokenizer\n",
        "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "    # Tokenize the data\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in data['text']:\n",
        "        inputs = tokenizer.encode_plus(text, add_special_tokens=True, max_length=128, pad_to_max_length=True,\n",
        "                                       return_attention_mask=True, return_tensors='tf')\n",
        "        input_ids.append(inputs['input_ids'])\n",
        "        attention_masks.append(inputs['attention_mask'])\n",
        "\n",
        "    input_ids = tf.concat(input_ids, axis=0)\n",
        "    attention_masks = tf.concat(attention_masks, axis=0)\n",
        "\n",
        "    # Ensure labels are in the same order and format as the inputs\n",
        "    labels = tf.convert_to_tensor(data['label'])\n",
        "\n",
        "    # Convert TensorFlow tensors to numpy arrays before splitting\n",
        "    input_ids = input_ids.numpy()\n",
        "    attention_masks = attention_masks.numpy()\n",
        "    labels = labels.numpy()\n",
        "\n",
        "    # Split the data\n",
        "    train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, random_state=2023, test_size=0.2)\n",
        "\n",
        "    # Convert the numpy arrays to string to return them\n",
        "    Outputs = namedtuple('Outputs', ['train_inputs', 'validation_inputs', 'train_labels', 'validation_labels'])\n",
        "\n",
        "    return Outputs(np.array2string(train_inputs), np.array2string(validation_inputs), np.array2string(train_labels), np.array2string(validation_labels))\n",
        "\n",
        "\n",
        "##@component\n",
        "# def train_model(data):\n",
        "#     # Similar code to your model training logic\n",
        "#     pass\n",
        "\n",
        "##@component\n",
        "# def save_model(bucket_name, model):\n",
        "#     # Similar code to your model saving logic\n",
        "#     pass\n",
        "\n",
        "##@component\n",
        "# def deploy_model(bucket_name, project_id, model_name):\n",
        "#     # Similar code to your model deployment logic\n",
        "#     pass\n"
      ],
      "metadata": {
        "id": "3yG6IIl4DM7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline"
      ],
      "metadata": {
        "id": "zHc_ODqSM1GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dsl.pipeline(\n",
        "    name='Training pipeline',\n",
        "    description='A pipeline that downloads, pre-processes data, trains a model, saves it and deploys it.'\n",
        ")\n",
        "def training_pipeline(bucket_name: str, file_name: str, project_id: str, model_name: str):\n",
        "    get_data_task = get_data(bucket_name=bucket_name, file_name=file_name)\n",
        "    preprocess_data_task = preprocess_data(csv_data=get_data_task.output)\n",
        "    # train_model_task = train_model(preprocess_data_task.output)\n",
        "    # save_model_task = save_model(bucket_name, train_model_task.output)\n",
        "    # deploy_model_task = deploy_model(bucket_name, project_id, model_name)\n"
      ],
      "metadata": {
        "id": "WTpZfdrFM1S5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile"
      ],
      "metadata": {
        "id": "lzf0d2U_PMxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the pipeline\n",
        "compiler.Compiler().compile(\n",
        "    pipeline_func=training_pipeline,\n",
        "    package_path='training_pipeline.json'\n",
        ")\n"
      ],
      "metadata": {
        "id": "Kw-YngmUPOGl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run"
      ],
      "metadata": {
        "id": "onzQXUCiPPic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import aiplatform\n",
        "\n",
        "# Define your GCP project ID and region\n",
        "region = 'us-central1'\n",
        "\n",
        "# Instantiate the client\n",
        "aiplatform.init(project=project_id, location=region)\n",
        "\n",
        "# Define the pipeline root (a Google Cloud Storage location)\n",
        "pipeline_root = 'gs://YOUR_BUCKET_NAME/PIPELINE_ROOT'\n",
        "\n",
        "# Define the display name for the pipeline job\n",
        "display_name = 'My Training Pipeline'\n",
        "\n",
        "# Define the pipeline job\n",
        "pipeline_job = aiplatform.PipelineJob(\n",
        "    display_name=display_name,\n",
        "    template_path='training_pipeline.json',\n",
        "    pipeline_root=pipeline_root\n",
        ")\n",
        "\n",
        "# Run the pipeline job\n",
        "pipeline_job.run()\n"
      ],
      "metadata": {
        "id": "myGuBHTIPSnY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}